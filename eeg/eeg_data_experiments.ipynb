{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:40:55.060233",
     "start_time": "2017-04-06T23:40:53.702528"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import keras as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "### Data ReadMe\n",
    "\n",
    "Kaneshiro_etAl_objectCategoryEEG_README.txt\n",
    "\n",
    "Data name: EEG data analyzed in \"A Representational Similarity Analysis of the Dynamics of Object Processing Using Single-Trial EEG Classification\"\n",
    "Creator: Blair Kaneshiro, blairbo@ccrma.stanford.edu\n",
    "PURL: http://purl.stanford.edu/bq914sc3730\n",
    "\n",
    "Preferred citation: Kaneshiro, Blair and Perreau Guimaraes, Marcos and Kim, Hyung-Suk and Norcia, Anthony M. and Suppes, Patrick (2015). EEG data analyzed in \"A Representational Similarity Analysis of the Dynamics of Object Processing Using Single-Trial EEG Classification\". Stanford Digital Repository. Available at: http://purl.stanford.edu/bq914sc3730\n",
    "\n",
    "The data package contains 10 anonymized datasets of scalp-recorded EEG in MATLAB (.mat) format. Each .mat file contains EEG data from one experimental subject. Data matrices have been preprocessed and are in the form used as input for classification. Dimensionality reduction/PCA has not been performed.\n",
    "\n",
    "Variables contained in each dataset\n",
    "- sub: Experimental subject identifier (e.g., 'S1', 'S2')\n",
    "- N: Number of time samples per trial (always 32)\n",
    "- Fs: Sampling frequency of the data (always 62.5Hz)\n",
    "- T: Number of experimental trials (around 5,184 per dataset)\n",
    "- exemplarLabels: A vector of length T containing the exemplar label of each trial.\n",
    "- categoryLabels: A vector of length T containing the category label of each trial. (1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object)\n",
    "- X: The data matrix. Size of X is T rows by 124*N columns. Each row of X represents one experimental trial. Trial labels are corresponding elements in the exemplarLabels and categoryLabels vectors. Columns of X contain N time samples of EEG, concatenated from 124 electrodes (i.e., N time samples from electrode 1 followed by N time samples from electrode 2, etc.). Electrode numbers correspond to channels 1-124 of EGI's HydroCel Geodesic Sensor Net, 128 channels (ftp://ftp.egi.com/pub/support/Documents/net_layouts/hcgsn_128.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Get the matlab files and extract the data/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:03.351321",
     "start_time": "2017-04-06T23:40:55.061606"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = ['data/S%d.mat' % (i+1) for i in range(10)]\n",
    "data = [scipy.io.loadmat(a_file) for a_file in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:03.363234",
     "start_time": "2017-04-06T23:41:03.352969"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fs', array([[ 62.5]]))\n",
      "('sub', array([u'S1'], \n",
      "      dtype='<U2'))\n",
      "('__globals__', [])\n",
      "('__header__', 'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Fri Feb  6 14:21:30 2015')\n",
      "('N', array([[32]], dtype=uint8))\n",
      "('T', array([[5188]], dtype=uint16))\n",
      "('X', array([[-0.26424164, -0.47586018, -0.47061757, ...,  0.05198565,\n",
      "         0.08307296, -0.04543913],\n",
      "       [ 0.0028675 , -0.04133774,  0.05108967, ...,  0.09525956,\n",
      "        -0.00872008,  0.12494965],\n",
      "       [-0.22358645,  0.02478356,  0.08543183, ...,  0.0938575 ,\n",
      "         0.06906053,  0.09690079],\n",
      "       ..., \n",
      "       [ 0.17795506, -0.06740315,  0.09080031, ..., -0.11675177,\n",
      "        -0.19592201, -0.16641006],\n",
      "       [ 0.18887348,  0.17863007,  0.32982534, ...,  0.10712342,\n",
      "         0.10700955,  0.0652873 ],\n",
      "       [ 0.02932549, -0.05199817, -0.15791252, ..., -0.09192452,\n",
      "        -0.04275392,  0.08084101]]))\n",
      "('__version__', '1.0')\n",
      "('exemplarLabels', array([[40, 64, 29, ..., 59,  3, 12]], dtype=uint8))\n",
      "('categoryLabels', array([[4, 6, 3, ..., 5, 1, 1]], dtype=uint8))\n",
      "[5188, 5185, 5186, 5186, 5185, 5186, 5188, 5184, 5185, 5184]\n",
      "[5188, 5185, 5186, 5186, 5185, 5186, 5188, 5184, 5185, 5184]\n"
     ]
    }
   ],
   "source": [
    "for key in data[0]:\n",
    "    print(key, data[0][key])\n",
    "    \n",
    "print([len(data[i]['X']) for i in range(len(data))])\n",
    "print([len(data[i]['categoryLabels'][0]) for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize the data\n",
    "Combine our data before shuffling. We set aside all data from a single subject as a special test that the model generalizes to new people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:07.606946",
     "start_time": "2017-04-06T23:41:03.365015"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('all test data shape:   ', (46673, 3968))\n",
      "('all test labels shape: ', (1, 46673))\n",
      "()\n",
      "('new person holdout data shape:   ', (5184, 3968))\n",
      "('new person holdout labels shape: ', (1, 5184))\n"
     ]
    }
   ],
   "source": [
    "all_data = np.array(data[0]['X'])\n",
    "all_labels = np.array(data[0]['categoryLabels'])\n",
    "\n",
    "for ind in range(len(data) - 2):\n",
    "    data_runner = data[ind+1]\n",
    "    all_data = np.concatenate((all_data, data_runner['X']))\n",
    "    all_labels = np.concatenate((all_labels, data_runner['categoryLabels']), axis=1)\n",
    "    \n",
    "test_new_person_data = data[len(data)-1]['X']\n",
    "test_new_person_labels = data[len(data)-1]['categoryLabels']\n",
    "\n",
    "print('all test data shape:   ', all_data.shape)\n",
    "print('all test labels shape: ', all_labels.shape)\n",
    "print()\n",
    "print('new person holdout data shape:   ', test_new_person_data.shape)\n",
    "print('new person holdout labels shape: ', test_new_person_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T19:49:13.790359",
     "start_time": "2017-04-06T19:49:13.770444"
    }
   },
   "source": [
    "shuffle the two lists, keeping their order matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:07.611348",
     "start_time": "2017-04-06T23:41:07.608304"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:12.590873",
     "start_time": "2017-04-06T23:41:07.612669"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffled_data, shuffled_labels = unison_shuffled_copies(all_data, all_labels.reshape(-1))\n",
    "shuffled_labels = shuffled_labels.reshape((-1, 1))\n",
    "\n",
    "    \n",
    "shuffled_labels = shuffled_labels - 1 # zero index the labels (3 -> 2)\n",
    "# shuffled_labels = keras.utils.np_utils.to_categorical(shuffled_labels) # change them to one-hot vectors (2 -> [0, 0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:12.595390",
     "start_time": "2017-04-06T23:41:12.592350"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46673, 3968)\n",
      "(46673, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_data.shape)\n",
    "print(shuffled_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T19:51:18.382634",
     "start_time": "2017-04-06T19:51:18.380133"
    },
    "collapsed": true
   },
   "source": [
    "split data into test and training portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:12.601599",
     "start_time": "2017-04-06T23:41:12.596670"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_portion = .1 # 10% of data reserved for final testing\n",
    "\n",
    "test_size = int(len(shuffled_data) * test_portion)\n",
    "\n",
    "test_data = shuffled_data[:test_size]\n",
    "test_labels = shuffled_labels[:test_size]\n",
    "\n",
    "training_data = shuffled_data[test_size:]\n",
    "training_labels = shuffled_labels[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:12.609126",
     "start_time": "2017-04-06T23:41:12.603894"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4667, 3968)\n",
      "(4667, 1)\n",
      "(42006, 3968)\n",
      "(42006, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:41:13.474332",
     "start_time": "2017-04-06T23:41:12.610665"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = k.models.Sequential()\n",
    "\n",
    "model.add(k.layers.core.Reshape((32, 124), input_shape=(3968,)))\n",
    "\n",
    "# model.add(k.layers.recurrent.GRU(32, dropout=.2, recurrent_dropout=.2, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
    "\n",
    "model.add(k.layers.recurrent.GRU(32, dropout=.2, recurrent_dropout=.2, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
    "model.add(k.layers.normalization.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "model.add(k.layers.convolutional.Conv1D(64, 16, padding='causal', activation='relu'))\n",
    "model.add(k.layers.normalization.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(k.layers.core.Dropout(.2))\n",
    "\n",
    "model.add(k.layers.convolutional.Conv1D(32, 4, padding='causal', activation='relu'))\n",
    "model.add(k.layers.normalization.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(k.layers.core.Dropout(.2))\n",
    "\n",
    "model.add(k.layers.Flatten())\n",
    "\n",
    "model.add(k.layers.Dense(24))\n",
    "model.add(k.layers.Activation('relu'))\n",
    "model.add(k.layers.core.Dropout(.2))\n",
    "\n",
    "model.add(k.layers.Dense(6))\n",
    "\n",
    "model.add(k.layers.Activation('softmax'))\n",
    "\n",
    "# print(model.layers[-1].output_shape)\n",
    "# print(model.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-06T23:43:41.447739",
     "start_time": "2017-04-06T23:41:13.475947"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37805 samples, validate on 4201 samples\n",
      "Epoch 1/20\n",
      "32s - loss: 1.7974 - acc: 0.1947 - val_loss: 1.7626 - val_acc: 0.2195\n",
      "Epoch 2/20\n",
      "33s - loss: 1.7477 - acc: 0.2224 - val_loss: 1.7123 - val_acc: 0.2568\n",
      "Epoch 3/20\n",
      "31s - loss: 1.7217 - acc: 0.2455 - val_loss: 1.6771 - val_acc: 0.2871\n",
      "Epoch 4/20\n",
      "32s - loss: 1.6951 - acc: 0.2654 - val_loss: 1.6496 - val_acc: 0.3097\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2dc2da6b1a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(training_data, training_labels, epochs=20, batch_size=100, verbose=2, shuffle=True, validation_split=.1)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(test_data, test_labels)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
